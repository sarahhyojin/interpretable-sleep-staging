{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(f'./Transformer-Explainability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import PIL\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "import ast\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baselines.ViT.ViT_Seq import sleep_inter_epoch as ViT_SLEEP_Inter\n",
    "from baselines.ViT.Seq_explanation_generator import LRP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load model with LRP to device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize InterEpoch ViT pretrained with vit_SLEEP\n",
    "model_path = \"/tf/data_AIoT1/ViT_models/Seq-Full-15-relprop-final-relu-2023-12-18.pth\"\n",
    "model = ViT_SLEEP_Inter(pretrained=True, checkpoint_path = model_path).cuda()\n",
    "model.eval()\n",
    "attribution_generator = LRP(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Argument setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = \"/tf/data_AIoT1/psg_image\"\n",
    "test_labels = \"/tf/data_AIoT1/psg_image/labels/test_1209.txt\"\n",
    "workers = 4\n",
    "batch_size = 128\n",
    "num_seq = 15\n",
    "save_path = \"/tf/data_AIoT1/psg_image_codes/confusion_matrix/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read test_labels\n",
    "df_file_list = pd.read_csv(test_labels, sep=\"\\t\", header=None)\n",
    "files = df_file_list[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create patient_dict\n",
    "patient_dict = {} # number of vectors that is from the same patient\n",
    "prev_patient = None\n",
    "\n",
    "for file in files:\n",
    "    patient = file[0:16]\n",
    "    if patient == prev_patient:\n",
    "        patient_dict[patient] += 1\n",
    "    else:\n",
    "        patient_dict[patient] = 1\n",
    "    prev_patient = patient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Functions\n",
    "- generate attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_attributions(image, num_seq):\n",
    "    attributions = []\n",
    "\n",
    "    for idx in range(num_seq):\n",
    "        transformer_attribution = attribution_generator.generate_LRP(image.unsqueeze(0).cuda(), method=\"transformer_attribution\", index=None, seq_idx=idx).detach()\n",
    "        transformer_attribution = transformer_attribution.squeeze()\n",
    "        # print(\"transformer_attribution\", transformer_attribution)\n",
    "        # print(\"transformer_attribution_sum\", transformer_attribution.sum())\n",
    "        # mask mine\n",
    "        transformer_attribution[idx] = 0\n",
    "        # print(\"transformer_attribution_sum_after_masking\", transformer_attribution.sum())\n",
    "        \n",
    "        # mask mine\n",
    "        transformer_attribution[idx] = 0\n",
    "        \n",
    "        # second smallest\n",
    "        values, indices = torch.topk(transformer_attribution, k=2, largest=False)\n",
    "        second_smallest_value = values[1].item()\n",
    "        \n",
    "        # normalize across each token\n",
    "        # min_value to be 0 and max_value to be 1\n",
    "        transformer_attribution = (transformer_attribution - second_smallest_value) / (transformer_attribution.max() - second_smallest_value)\n",
    "        \n",
    "        transformer_attribution = transformer_attribution.data.cpu().numpy()\n",
    "        # print(\"after_normalization\", transformer_attribution)\n",
    "        # print(\"transformer_attribution_sum_after_normalization\", transformer_attribution.sum())\n",
    "        # set mine attention as 1\n",
    "        transformer_attribution[idx] = 1\n",
    "        attributions.append(transformer_attribution)\n",
    "\n",
    "    # Normalize\n",
    "    # attributions = (attributions - np.min(attributions)) / (np.max(attributions) - np.min(attributions))\n",
    "    # print(attributions)\n",
    "    return attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_windows_relprop(patient_vector, num_seq, batch_size, length, model, device):\n",
    "    \"\"\"\n",
    "    [INPUT]\n",
    "    patient_vector : extracted feature vectors per image and concatenated from one patient\n",
    "    num_seq : sliding window's kernel size\n",
    "    batch_size : batch size to be processed\n",
    "    length : length of the total epoch of one patient\n",
    "    model : trained model\n",
    "    \n",
    "    [OUTPUT]\n",
    "    final_pred = final predictions with softmax for each sliding window\n",
    "    final_attributions = Patient's attributions for each epoch.\n",
    "    final_agg = final aggregated softmax value - one value per epoch\n",
    "    final_lbl = final prediction label for each sliding window\n",
    "    \"\"\"\n",
    "    final_attributions = [[] for _ in range(length)]\n",
    "    final_pred = [[] for _ in range(length)]\n",
    "    final_agg = [torch.tensor([0, 0, 0, 0, 0], dtype=torch.float32, device=device) for _ in range(length)]\n",
    "    final_lbl = [[] for _ in range(length)]\n",
    "    current_seq = []\n",
    "\n",
    "    for i in tqdm(range(length - num_seq + 1)):\n",
    "        current_seq.append(patient_vector[i:i+num_seq])\n",
    "        current_lbl = lbl[i:i+num_seq]\n",
    "        \n",
    "        # iterate for labels\n",
    "        for j in range(i, i+num_seq):\n",
    "            final_lbl[j].append(current_lbl)\n",
    "            \n",
    "        if (i+1) % batch_size == 0:\n",
    "            batch_seq = torch.stack(current_seq).to(device)\n",
    "            current_seq = []\n",
    "            output = model(batch_seq)\n",
    "\n",
    "            for k in range(batch_size):  # batch\n",
    "                attributions = generate_attributions(batch_seq[k], num_seq)\n",
    "                temp_pred = []\n",
    "                for j in range(num_seq):\n",
    "                    # append the output of the predictions(?)\n",
    "                    # append the attributions\n",
    "                    # append the current predictions and total aggregated prediction\n",
    "                    final_agg[k + j + i - (batch_size-1)].add_(torch.softmax(output[j][k], dim=0))\n",
    "                    final_attributions[k + i + j - (batch_size-1)].append(attributions[j])\n",
    "                    soft_val = torch.softmax(output[j][k], dim=0)\n",
    "                    _, predict = soft_val.max(dim=0)\n",
    "                    temp_pred.append(predict.item())\n",
    "                for p in range(k + i - (batch_size-1), k + i - (batch_size-1) + num_seq):\n",
    "                    final_pred[p].append(temp_pred)\n",
    "                \n",
    "    \n",
    "    # for remainder\n",
    "    if len(current_seq) != 0:\n",
    "        batch_seq = torch.stack(current_seq).to(device)\n",
    "        output_2 = model(batch_seq)\n",
    "\n",
    "        new_i = batch_size * ((length - num_seq + 1)//batch_size)\n",
    "\n",
    "        for k in range(output_2[0].shape[0]):  # batch\n",
    "            attributions_2 = generate_attributions(batch_seq[k], num_seq)\n",
    "            temp_pred = []\n",
    "            for j in range(num_seq):  # sequence length\n",
    "                final_agg[k + j + new_i].add_(torch.softmax(output_2[j][k], dim=0))\n",
    "                final_attributions[k + j + new_i].append(attributions_2[j])\n",
    "                # get prediction by sequence\n",
    "                soft_val = torch.softmax(output_2[j][k], dim=0)\n",
    "                _, predict = soft_val.max(dim=0)\n",
    "                temp_pred.append(predict.item())\n",
    "            for p in range(k + new_i, k + new_i + num_seq):\n",
    "                final_pred[p].append(temp_pred)\n",
    "    \n",
    "    return final_pred, final_attributions, final_agg, final_lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for patient, length in patient_dict.items():\n",
    "    hospital = '-'.join(patient.split('-')[:-1])\n",
    "    patient_folder = os.path.join(img_dir, hospital, \"vectors_v2\", patient) # change vectors_v2 here\n",
    "    if not os.path.exists:\n",
    "        print(patient_folder)\n",
    "    temp = []\n",
    "    lbl = []\n",
    "    patient_epoch = df_file_list[df_file_list[0].str.startswith(patient)]\n",
    "    sorted_epoch = patient_epoch.sort_values(by=0)\n",
    "    # sorted_epoch = sorted(os.listdir(patient_folder))\n",
    "    # print(sorted_epoch)\n",
    "    for index, row in sorted_epoch.iterrows():\n",
    "        # print(f\"Loading {i}th vector\")\n",
    "        file_name = row[0][:-4] + \"_\" + str(row[1]) + \".npy\"\n",
    "        vector_np = torch.from_numpy(np.load(os.path.join(patient_folder, file_name)).astype(np.float32))\n",
    "        temp.append(vector_np)\n",
    "        lbl.append(row[1])\n",
    "        # print(len(temp))\n",
    "    patient_vector = torch.stack(temp)\n",
    "\n",
    "    final_pred, final_attributions, final_agg, final_lbl = sliding_windows_relprop(patient_vector=patient_vector,\n",
    "                                                                        num_seq=num_seq,\n",
    "                                                                        batch_size = batch_size,\n",
    "                                                                        length = length, model = model,\n",
    "                                                                        device=device)\n",
    "    # do for just one patient\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change the middle labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patheffects import withStroke\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualization_for_v2(final_pred, final_attributions, final_agg, final_lbl):\n",
    "    \n",
    "    # get aggregated predictions for current epoch\n",
    "    labels_map = {0:'W', 1:'N1', 2:'N2', 3:'N3', 4:'R'}\n",
    "\n",
    "    for epoch in range(len(final_pred)):\n",
    "        pred = final_pred[epoch] # predictions vector\n",
    "        attributions = final_attributions[epoch] # attributions vector\n",
    "        agg = final_agg[epoch] # aggregated prediction for this epoch(1)\n",
    "        lbl = final_lbl[epoch] # aggregated label (1)\n",
    "\n",
    "        rolled_attributions = [[0 for _ in range(num_seq * 2 - 1)] for _ in range(len(pred))]\n",
    "\n",
    "        for i in range(len(attributions)):\n",
    "            for j in range(i, i+num_seq):\n",
    "                rolled_attributions[i][j] = attributions[i][j-i]\n",
    "                \n",
    "        rolled_predictions = [[None for _ in range(num_seq * 2 - 1)] for _ in range(len(attributions))]\n",
    "\n",
    "        for i in range(len(pred)):\n",
    "            for j in range(i, i+num_seq):\n",
    "                # make the target sequence as 0\n",
    "                if epoch < 14:\n",
    "                    rolled_attributions[i][epoch] = 0\n",
    "                else:\n",
    "                    rolled_attributions[i][14] = 0\n",
    "                rolled_predictions[i][j] = labels_map[pred[i][j-i]]\n",
    "                \n",
    "        new_lbl = lbl[0][:-1] + lbl[-1]\n",
    "                \n",
    "        # Create a figure and axis object\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "        # Plot the rolled_attributions\n",
    "        cmap = plt.cm.get_cmap('hot_r')\n",
    "        im = ax.imshow(rolled_attributions, cmap=cmap, aspect='auto')\n",
    "        ax.set_aspect('equal')\n",
    "\n",
    "        # Add colorbar\n",
    "        plt.colorbar(im, shrink=0.5)\n",
    "\n",
    "        # Calculate predictions and set title\n",
    "        prob = torch.softmax(agg, dim=0)\n",
    "        _, pred = prob.max(dim=0)\n",
    "        pred_label = labels_map[pred.item()]\n",
    "        ax.set_title(f'Epoch {epoch} | Prediction: {pred_label}', fontsize = 10)\n",
    "\n",
    "        # Set labels\n",
    "        ax.set_ylabel('Sliding Windows')\n",
    "        ax.set_xlabel('GT Labels')\n",
    "\n",
    "        # Set ticks\n",
    "        ax.set_xticks(np.arange(len(new_lbl)))\n",
    "        ax.set_yticks(np.arange(num_seq))\n",
    "\n",
    "        labels = []\n",
    "        for l in new_lbl:\n",
    "            # print(l)\n",
    "            labels.append(labels_map[l])\n",
    "\n",
    "        ax.set_xticklabels(labels)\n",
    "\n",
    "\n",
    "        # Put predictions labels on the cell\n",
    "        for i in range(len(rolled_predictions)):\n",
    "            for j, txt in enumerate(rolled_predictions[i]):\n",
    "                # ax.text(j, i, txt, color=\"white\", ha=\"center\", va=\"center\")\n",
    "                if epoch < 14 and j == epoch:\n",
    "                    ax.text(j, i, txt, color=\"black\", ha=\"center\", va=\"center\")\n",
    "                elif epoch >= 14 and j == 14:\n",
    "                    ax.text(j, i, txt, color=\"black\", ha=\"center\", va=\"center\")\n",
    "                else:\n",
    "                    ax.text(j, i, txt, color=\"white\", ha=\"center\", va=\"center\")\n",
    "        \n",
    "        # Add borders around each cell\n",
    "        for i in range(len(rolled_attributions)):\n",
    "            for j in range(len(rolled_attributions[i])):\n",
    "                if epoch < 14 and j == epoch:\n",
    "                    rect = patches.Rectangle((j - 0.5, i - 0.5), 1, 1, linewidth=1, edgecolor='black', facecolor='none')\n",
    "                    ax.add_patch(rect)\n",
    "                elif epoch >= 14 and j == 14:\n",
    "                    rect = patches.Rectangle((j - 0.5, i - 0.5), 1, 1, linewidth=1, edgecolor='black', facecolor='none')\n",
    "                    ax.add_patch(rect)\n",
    "                else:\n",
    "                    continue\n",
    "            \n",
    "        # Show the plot\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualization_for_v2(final_pred, final_attributions, final_agg, final_lbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do for the second patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_inter_epoch_visualization(patient, length):\n",
    "    hospital = '-'.join(patient.split('-')[:-1])\n",
    "    patient_folder = os.path.join(img_dir, hospital, \"vectors_v2\", patient) # change vectors_v2 here\n",
    "    if not os.path.exists:\n",
    "        print(patient_folder)\n",
    "    temp = []\n",
    "    lbl = []\n",
    "    patient_epoch = df_file_list[df_file_list[0].str.startswith(patient)]\n",
    "    sorted_epoch = patient_epoch.sort_values(by=0)\n",
    "    # sorted_epoch = sorted(os.listdir(patient_folder))\n",
    "    # print(sorted_epoch)\n",
    "    for index, row in sorted_epoch.iterrows():\n",
    "        # print(f\"Loading {i}th vector\")\n",
    "        vector_np = torch.from_numpy(np.load(os.path.join(patient_folder, row[0])).astype(np.float32))\n",
    "        temp.append(vector_np)\n",
    "        lbl.append(row[1])\n",
    "        # print(len(temp))\n",
    "    patient_vector = torch.stack(temp)\n",
    "\n",
    "    final_pred, final_attributions, final_agg, final_lbl = sliding_windows_relprop(patient_vector=patient_vector,\n",
    "                                                                        num_seq=num_seq,\n",
    "                                                                        batch_size = batch_size,\n",
    "                                                                        length = length, model = model,\n",
    "                                                                        device=device)\n",
    "    \n",
    "    return final_pred, final_attributions, final_agg, final_lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(31)\n",
    "patient, length = random.choice(list(patient_dict.items()))\n",
    "print(patient, length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "random_pred, random_attributions, random_agg, random_lbl = generate_inter_epoch_visualization(patient, length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visualization_for_v2(random_pred, random_attributions, random_agg, random_lbl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
